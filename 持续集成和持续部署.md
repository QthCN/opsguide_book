# 持续集成和持续部署

## 持续集成

持续集成和持续部署经常会放在一起讲，本节我们先来看下持续集成。持续集成其主要的含义就是保证代码库里的代码只要在持续集成环境亮绿灯，那么就能直接部署到产线。对于一般的代码上线流程来说，代码从开发提交代码到仓库一直到部署到产线，一般会经过代码提交、代码合并、运行单元测试、打包、运行集成及功能测试、部署到预发环境、部署到产线环境这几步。而持续集成涵盖的步骤包括从代码提交一直到运行集成及功能测试的这几步。那持续集成和普通的从提交一直到运行集成及功能测试的过程有什么区别呢？区别主要在于对于开发的每一次提交，系统都会自动的进行所有这些步骤，并且如果这次提交可以通过所有测试并最终打包成功，那么持续集成的状态就会亮绿灯，否则如果这些步骤中有任何一步出现了问题，例如某个测试用例没有通过，那么持续集成的状态就是红灯，对于持续集成来说如果亮了红灯就要立刻进行修复，保证仓库里的代码一直处于随时可部署到产线的状态。而传统的流程则是统一定下几个日期，例如每周二是封板日，在这个日子开发会提交所有代码到仓库，然后就不能提交了，而测试人员则在这个时间点后开始测试，一直到发布日（例如周四）如果测试没有问题的话就会进行打包和测试然后发布到产线。相比较传统的流程，持续集成的流程将这一流程的执行频率提高到了每次提交，并且将测试的工作尽可能自动化，减少会取消测试人员的参与，持续集成就好像一条流水线，在流水线上代码合并、运行测试等步骤有条不紊的运行。持续集成的优点主要有：它取消了固定的发布日，这样对于产品来说迭代的速度回加快，而传统的发布可能要两周才有一个发布日，那么对于产品的迭代是比较慢的。同时持续集成保证了仓库中代码的质量，能及早发现并修复问题。但持续集成对测试用例的要求比较高，必须采用测试驱动的方法进行开发，保证足够的单元测试，并且对于集成及功能测试需要有对应的测试框架，另外由于整个流程使用了自动化的流水线的方式，因此需要具体的平台支持持续集成的流水线操作。由于本书的读者群主要是运维，大部分运维对测试驱动开发不熟悉，而测试驱动开发在持续集成和持续部署中又占据了非常重要的作用，因此这里介绍下测试驱动开发。

## 测试驱动开发

测试驱动开发（TDD），顾名思义就是通过测试驱动开发。最好的说明什么是测试驱动开发的办法就是举一个例子，这里笔者举一个判断一个数是否是偶数的例子。我们的例子的目录结构如下，其中bt.py存放我们的功能代码，其中会包括一个函数is_even，它能接收一个参数，如果这个参数是偶数则is_even返回True，否则返回False。而bt_test.py中存放我们的测试代码。

```python
(python3.5)➜  tdd ls -l
total 16
-rw-r--r--  1 thuanqin  wheel   32  6 29 22:22 bt.py
-rw-r--r--  1 thuanqin  wheel  147  6 29 22:24 bt_test.py
```

现在我们希望is_even对于偶数能正确的返回True，所以按照这个思路，我们来写个测试用例，用例做的事情就是我们所希望的那样，传给is_even一个偶数，看下它返回的是不是True：

```python
(python3.5)➜  tdd cat bt_test.py
import nose

from bt import is_even


def test_is_even_by_num_2():
    assert is_even(2) == True


if __name__ == "__main__":
    nose.runmodule()
```

这里我们使用了nose这个库用于辅助我们的单元测试。我们这里的测试代码很简单，传一个2给is_even，看下其是不是返回True。我们运行这个测试用例：

```python
(python3.5)➜  tdd python bt_test.py
Traceback (most recent call last):
  File "bt_test.py", line 3, in <module>
    from bt import is_even
ImportError: cannot import name 'is_even'
```

可以看到它报错了，报错提示说is_even无法被import，因此测试没有通过。这很正常，因为我们还没开始在bt.py中实现我们的is_even函数。读者如果觉得这里很傻那是正常的，但测试驱动就是这样在很傻的表面下进行不停的开发。当我们的代码越来越复杂后，有一天某个新来的人增加了一个功能，不小心在重构的时候删除了一点代码，例如删除了is_even，那么我们这里的这个看似很傻的测试就会及时暴露这个问题。现在让我们来实现is_even：

```python
(python3.5)➜  tdd cat bt.py
def is_even(num):
    return True
(python3.5)➜  tdd python bt_test.py
.
----------------------------------------------------------------------
Ran 1 test in 0.001s

OK
```
可以看到我们的代码通过了测试。当然啦，我们这里代码肯定是会通过测试的，因为我们直接对结果返回了True。这样做明显是为了通过测试而测试，但读者要记住，只要测试用例覆盖了满足业务需求的所有情况，那么为了通过测试而测试是正确的做法。我们这里的问题在于我们的测试用例太少，并没有涵盖足够的情况。一般读者在写测试用例的时候可以对照着业务需求文档或接口文档等实现对应的测试用例。我们这里来增加一个测试用例：

```python
(python3.5)➜  tdd cat bt_test.py
import nose

from bt import is_even


def test_is_even_by_num_2():
    assert is_even(2) == True


def test_is_even_by_num_3():
    assert is_even(3) == False


if __name__ == "__main__":
    nose.runmodule()
```

按照我们的需求，对于偶数我们要返回True，而对于奇数则需要返回False，因此我们写下了test_is_even_by_num_3这个测试用例。现在再来运行我们的测试代码看下是否能通过测试：

```bash
(python3.5)➜  tdd python bt_test.py
.F
======================================================================
FAIL: __main__.test_is_even_by_num_3
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/Users/thuanqin/Desktop/Dev/lab/python3.5/lib/python3.5/site-packages/nose/case.py", line 198, in runTest
    self.test(*self.arg)
  File "bt_test.py", line 11, in test_is_even_by_num_3
    assert is_even(3) == False
AssertionError

----------------------------------------------------------------------
Ran 2 tests in 0.003s

FAILED (failures=1)
```

可以看到结果中提示有一个测试用例没有通过。为了通过这个测试我们来修改我们的is_even，修改后的is_even如下：

```python
(python3.5)➜  tdd cat bt.py
def is_even(num):
    return num % 2 == 0
```

然后再来运行我们的测试代码：

```bash
(python3.5)➜  tdd python bt_test.py
..
----------------------------------------------------------------------
Ran 2 tests in 0.001s

OK
```

可以看到我们的两个测试用例都通过了。那我们是否还需要再新增测试用例呢？例如我们可以新增浮点数、负数、甚至是传递个字符处的测试用例，这些测试用例是否需要的前提需要根据实际的要求文档进行编写，如果is_even的接口文档的说明里明确列出了参数必须是正整数那么就不需要这些测试用例了。

在测试驱动开发中会遇到一些问题，最常见的一个问题就是测试代码涉及到外部系统、外部接口的交互。对于这类问题解决起来需要做到两点，一个是有一个足够强大的Mock库，另一个则是代码中对于外部系统的调用都需要走接口，在实际的业务代码中传入外部系统的代理对象，而在测试代码中则传入Mock过的实现了该接口的对象。此时判断一个测试用例是否通过的标准也有一些不同，会从判断被测试代码的返回值变为判断对Mock的代理对象的调用参数是否构造正确、Mock的代理对象的调用次数是否符合逻辑等等。

## 持续部署

前面我们简单介绍了持续集成，并说明了一下持续集成中非常重要的测试驱动开发是什么。这里我们来说下持续部署。在持续集成的小节中我们说过，一个代码提交后会依次经过代码合并、运行单元测试、打包、运行集成及功能测试、部署到预发环境、部署到产线环境这几步，既然持续集成包括了从提交一直到打包、测试的所有步骤，那么持续部署就是指的系统自动的将代码部署到预发及产线的步骤。实质上持续部署系统囊括了持续集成，也就是说对于实现了持续部署的系统，例如一个网页应用，开发一次提交后，持续部署系统会自动的进行所有的这些步骤，顺利的话开发提交完代码，等待一会，然后去刷新下页面就能看到新功能生效了。无论是从实现难度还是说与业务放的标准约定来说，持续部署都非常具有挑战。但对于真正实现了持续部署的公司来说，他们能保证所有运行到产线的代码都经过了严格的测试，并且新功能上线及紧急bug fix都能做的非常迅速。由于本书的目标之一就是实现一个自动化的运维系统，而持续部署也是其功能之一，因此在本书的后续章节我们会一步一步朝着这个目标迈进。不过在这之前，我们先来看下目前常见的持续集成及持续部署工具。

## gitlab和jenkins

gitlab可以认为就是github的『私有云』版本。借助gitlab企业可以在自己的公司中搭建一个私有的git托管库，gitlab提供了非常强大的管理页面，并且gitlab还提供了自带的CI工具。笔者在上面已经提到，持续集成/持续部署都始于代码的提交，而gitlab则是代码提交后代码的存放地，因此其地位是非常重要的。这里我们来看下如何在自己的企业内部安装一套gitlab。

首先可以从https://about.gitlab.com/这个网站上下载具体的安装包，这里我们选择Community Edition版本，点击download后会跳转到一个选择OS版本的页面，我们选择CentOS7。接着就会看到网页上列出了如下的安装命令：

```bash
sudo yum install curl policycoreutils openssh-server openssh-clients
sudo systemctl enable sshd
sudo systemctl start sshd
sudo yum install postfix
sudo systemctl enable postfix
sudo systemctl start postfix
sudo firewall-cmd --permanent --add-service=http
sudo systemctl reload firewalld

curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash
sudo yum install gitlab-ce

sudo gitlab-ctl reconfigure
```

可以看到整个安装过程非常简单，全靠gitlab-ctl reconfigure来完成。但从上面的命令我们可以看到gitlab依赖了postfix等组件，并且实际上其还依赖了nginx、ruby等组件。那为什么这么多组件的安装只要一个命令就能实现呢？原因在于gitlab的整个安装过程是基于Chef的，Chef是一个配置管理工具，目前我们可以认为其包裹了一系列的安装脚本，在后面的章节我们会详细看下Chef、Puppet、SaltStack实际使用和功能。这里笔者建议大家可以安装一下试试，感觉一些这种安装方式带来的便捷。

接下来我们来看jenkins。jenkins原名Hudson，最早是由Sun公司开发的一款由Java编写的CI工具，主要使用了Java的Servlet，因此可以跑在大部分J2EE WEB中间件上。由于互联网泡沫的破裂，Sun公司后来被Oracle收购，与此同时Sun公司的Java、MySQL、Hudson等都一并被Oracle获得。但Oracle公司不希望维持Sun原有的对Hudson的开源态度，因此Hudson的开发者就离开了Oracle公司，并重新fork了一份代码，在此基础上继续开发功能，而新的这份代码就改名为jenkins。这一点和MariaDB及MySQL的关系很像。

简单的说，通过jenkins我们可以配置整个CI流程每一步由什么工具进行什么工作，在jenkins中一次完整的操作称为『任务』。假如我们的代码目前被提交到了gitlab上，那么我们可以在jenkins中配置一个git插件，我们可以在插件中配置具体的项目所在的gitlab地址，指定分支，并设定触发动作，这个动作可以是执行一系列的shell脚本。然后当我们有代码提交到gitlab上后，jenkins就会发现有代码提交了，并且在比较了触发逻辑后（例如检查分支信息）就会执行我们的shell脚本，而我们的shell脚本就可以执行诸如运行测试代码、打包、上传打包文件到包管理仓库中去等操作。读者可能会觉得这些功能通过一个脚本也能实现，确实如果单独的看一两个打包任务的话通过脚本就能实现，但通过jenkins可以同时处理非常多的任务，jenkins会自动的根据主机情况对任务进行排队，同时jenkins有非常多的扩展可用，几乎支持大部分常用的语言。并且jenkins还有一个UI页面，可以让用户看到自己的任务目前进行到哪一步了，或者可以了解到哪一步出了问题。

就目前笔者所看到的持续集成工具链来说，基于gitlab+jenkins是最常见的组合。因此对于想尝试持续集成/持续部署的读者来说，从这两个工具入门可以找到足够多的帮助资料及最佳实践。

## 基于docker的持续部署

在本书实现的运维平台中，被打包及部署的对象分别是docker镜像及docker容器。因此这里简单介绍下基于docker的持续部署。流程如下：

* 开发提交代码到gitlab。这里的代码包括一个Dockerfile，并且该Dockerfile可以将代码打包成一个镜像
* 评审代码，如果没有问题的话合并到打包分支
* jenkins发现打包分支有提交，开始进行CI流程
* jenkins运行单元测试，执行代码中的单元测试代码
* jenkins将代码根据代码中的Dockerfile打包成一个镜像
* jenkins将打包好的镜像上传到私有的docker仓库中
* jenkins触发功能及集成测试平台进行功能及集成测试
* 功能及集成测试平台从私有docker仓库中拉取镜像，构建环境进行测试
* 如果测试通过，功能及集成测试平台将信息同步到部署平台
* 部署平台触发预发部署、灰度部署等操作，并根据实际配置进行产线部署

这个流程中有几点需要注意，例如由于我们的代码要能被打包成一个镜像，因此对于代码的配置文件指定方式、镜像的持久化容器配置、端口映射等等都要有相应的标准。同时不同公司都有不同的现存系统及打包方式，如果读者要使用这套流程的话需要结合自己公司的实际情况进行判断。
